{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c8296d8",
   "metadata": {},
   "source": [
    "# REBEL MODEL\n",
    "\n",
    "Paper: https://aclanthology.org/2021.findings-emnlp.204.pdf\n",
    "\n",
    "Git: https://github.com/Babelscape/rebel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3097800",
   "metadata": {},
   "source": [
    "## Rebel Models Triplet extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1418ae6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import re\n",
    "\n",
    "# --- Parsing functions ---\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_triplets_mrebel(text):\n",
    "    # Remove language tokens\n",
    "    text = re.sub(r\">>.*?<<\", \"\", text)\n",
    "    triplets = []\n",
    "    # Split by <triplet>\n",
    "    for triplet_str in text.split(\"<triplet>\"):\n",
    "        triplet_str = triplet_str.strip()\n",
    "        if not triplet_str:\n",
    "            continue\n",
    "        # Find all type tokens and their positions\n",
    "        matches = list(re.finditer(r\"<[^>]+>\", triplet_str))\n",
    "        if len(matches) < 2:\n",
    "            continue\n",
    "        # Subject is before first type token\n",
    "        subject = triplet_str[:matches[0].start()].strip()\n",
    "        subject_type = matches[0].group(0).replace(\"<\", \"\").replace(\">\", \"\").capitalize()\n",
    "        # Object is after second type token\n",
    "        object_ = triplet_str[matches[1].end():].strip()\n",
    "        object_type = matches[1].group(0).replace(\"<\", \"\").replace(\">\", \"\").capitalize()\n",
    "        # TAIL is between the two type tokens\n",
    "        TAIL = triplet_str[matches[0].end():matches[1].start()].strip()\n",
    "        # Remove any type tokens from subject/object\n",
    "        subject = re.sub(r\"<[^>]+>\", \"\", subject).strip()\n",
    "        object_ = re.sub(r\"<[^>]+>\", \"\", object_).strip()\n",
    "        # Split if there are multiple relations/entities (by double/triple spaces or '  ')\n",
    "        for rel, obj in zip(TAIL.split(\"  \"), object_.split(\"  \")):\n",
    "            rel = rel.strip()\n",
    "            obj = obj.strip()\n",
    "            if subject and rel and obj:\n",
    "                triplets.append({\n",
    "                    'head': subject,\n",
    "                    'head_type': subject_type,\n",
    "                    'type': rel,\n",
    "                    'RELATION': obj,\n",
    "                    'tail_type': object_type\n",
    "                })\n",
    "    return triplets\n",
    "\n",
    "def extract_triplets_rebel(text):\n",
    "    # Remove language tokens\n",
    "    text = re.sub(r\">>.*?<<\", \"\", text)\n",
    "    triplets = []\n",
    "    # Split by <triplet>\n",
    "    for triplet_str in text.split(\"<triplet>\"):\n",
    "        triplet_str = triplet_str.strip()\n",
    "        if not triplet_str:\n",
    "            continue\n",
    "        # Format: subject <subj> TAIL <obj> object\n",
    "        subj_match = re.search(r\"(.*?)<subj>\", triplet_str)\n",
    "        rel_match = re.search(r\"<subj>(.*?)<obj>\", triplet_str)\n",
    "        obj_match = re.search(r\"<obj>(.*)\", triplet_str)\n",
    "        if subj_match and rel_match and obj_match:\n",
    "            subject = subj_match.group(1).strip()\n",
    "            TAIL = rel_match.group(1).strip()\n",
    "            object_ = obj_match.group(1).strip()\n",
    "            # Remove any tags accidentally left\n",
    "            subject = re.sub(r\"<[^>]+>\", \"\", subject).strip()\n",
    "            TAIL = re.sub(r\"<[^>]+>\", \"\", TAIL).strip()\n",
    "            object_ = re.sub(r\"<[^>]+>\", \"\", object_).strip()\n",
    "            if subject and TAIL and object_:\n",
    "                triplets.append({\n",
    "                    'head': subject,\n",
    "                    'head_type': '',\n",
    "                    'type': TAIL,\n",
    "                    'RELATION': object_,\n",
    "                    'tail_type': ''\n",
    "                })\n",
    "    return triplets\n",
    "\n",
    "# --- Device selection ---\n",
    "device_to_use = 0 if torch.cuda.is_available() else -1\n",
    "print(f\"Using device: {'cuda:' + str(device_to_use) if device_to_use != -1 else 'cpu'}\")\n",
    "\n",
    "# --- Pipelines ---\n",
    "triplet_extractor_mrebel = pipeline(\n",
    "    'translation',\n",
    "    model='Babelscape/mrebel-large',\n",
    "    tokenizer='Babelscape/mrebel-large',\n",
    "    device=device_to_use\n",
    ")\n",
    "triplet_extractor_rebel = pipeline(\n",
    "    'text2text-generation',\n",
    "    model='Babelscape/rebel-large',\n",
    "    tokenizer='Babelscape/rebel-large',\n",
    "    device=device_to_use\n",
    ")\n",
    "\n",
    "df = pd.read_csv('JuanRana_split.csv')\n",
    "all_triplets = []\n",
    "\n",
    "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing documents\"):\n",
    "    document = row['ID']\n",
    "    text = row['Text']\n",
    "\n",
    "    # --- mREBEL ---\n",
    "    try:\n",
    "        output = triplet_extractor_mrebel(\n",
    "            text,\n",
    "            src_lang=\"es_XX\",\n",
    "            tgt_lang=\"es_XX\",\n",
    "            max_length=400,\n",
    "            return_tensors=True,\n",
    "            return_text=False\n",
    "        )[0][\"translation_token_ids\"]\n",
    "        decoded = triplet_extractor_mrebel.tokenizer.batch_decode([output], skip_special_tokens=False)[0]\n",
    "        triplets_mrebel = extract_triplets_mrebel(decoded)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row {index} with mREBEL: {e}\")\n",
    "        triplets_mrebel = []\n",
    "\n",
    "    # --- REBEL ---\n",
    "    try:\n",
    "        output = triplet_extractor_rebel(\n",
    "            text,\n",
    "            max_length=400,\n",
    "            return_tensors=True,\n",
    "            return_text=False\n",
    "        )[0][\"generated_token_ids\"]\n",
    "        decoded = triplet_extractor_rebel.tokenizer.batch_decode([output], skip_special_tokens=False)[0]\n",
    "        triplets_rebel = extract_triplets_rebel(decoded)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row {index} with REBEL: {e}\")\n",
    "        triplets_rebel = []\n",
    "\n",
    "    # --- Append ---\n",
    "    for i, triplet in enumerate(triplets_mrebel, 1):\n",
    "        all_triplets.append({\n",
    "            \"DOCUMENT\": document,\n",
    "            \"SUBLABEL\": i,\n",
    "            \"MODEL\": \"mrebel\",\n",
    "            \"HEAD\": triplet.get('head', ''),\n",
    "            \"TAIL\": triplet.get('type', ''),\n",
    "            \"RELATION\": triplet.get('RELATION', ''),\n",
    "            \"HEAD_TYPE\": triplet.get('head_type', ''),\n",
    "            \"TAIL_TYPE\": triplet.get('tail_type', '')\n",
    "        })\n",
    "    for i, triplet in enumerate(triplets_rebel, 1):\n",
    "        all_triplets.append({\n",
    "            \"DOCUMENT\": document,\n",
    "            \"SUBLABEL\": i,\n",
    "            \"MODEL\": \"rebel\",\n",
    "            \"HEAD\": triplet.get('head', ''),\n",
    "            \"TAIL\": triplet.get('type', ''),\n",
    "            \"RELATION\": triplet.get('RELATION', ''),\n",
    "            \"HEAD_TYPE\": triplet.get('head_type', ''),\n",
    "            \"TAIL_TYPE\": triplet.get('tail_type', '')\n",
    "        })\n",
    "\n",
    "result_df = pd.DataFrame(all_triplets)\n",
    "result_df.to_csv('triplets_output.csv', index=False)\n",
    "print(\"Processing complete. Triplets saved to triplets_output.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
